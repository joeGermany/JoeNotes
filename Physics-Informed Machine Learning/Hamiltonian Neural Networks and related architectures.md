The foundational paper on Hamiltonian dynamics and machine learning is Greydanus et al.'s "[[Hamiltonian Neural Networks]]"[^1] (HNNs). Many refinements, additions, changes have been suggested since its publication. One of the earlier exploration were [[Symplectic Recurrent Neural Networks]], which adopted a recurrent neural network architecture to deal with the time series data and incorporated a symplectic integrator to try to preserve the structure of the Hamiltonian and increase accuracy. 

- [[Symplectic ODE-Net]]
- [[Hamiltonian Graph Networks with ODE Integrators]]
- [[Nonseparable Symplectic Neural Networks]]
- [[Taylor-Net]]
- [[Simplifying Hamiltonian and Lagrangian Neural Networks via Explicit Constraints]]
- 

## Lagrangian-related Neural Network Architectures
- [[Lagrangian Neural Networks]]
- [[Deep Lagrangian Networks]]

## Port-Hamiltonian Networks
- 

[^1]:  Greydanus, S., Dzamba, M., & Yosinski, J. (2019). Hamiltonian Neural Networks. [https://arxiv.org/abs/1906.01563](https://arxiv.org/abs/1906.01563)
